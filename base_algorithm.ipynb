{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base_model 1_(DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten, BatchNormalization, Activation\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "\n",
    "# Assuming the images are resized/preprocessed to 60x60 grayscale\n",
    "input_shape = (224, 224, 1) # Last dimension 1 for grayscale\n",
    "\n",
    "model = Sequential([\n",
    "    # Flattening the 60x60 input image to a 3600-element vector\n",
    "    Flatten(input_shape=input_shape),\n",
    "    \n",
    "    # Example of adding a few hidden layers with batch normalization and ReLU activation\n",
    "    Dense(512, kernel_initializer=HeNormal()), # He initialization\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "\n",
    "    Dense(256, kernel_initializer=HeNormal()),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    # Output layer for binary classification\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilation of the model using Adadelta optimizer and binary crossentropy loss\n",
    "# since this is a binary classification problem\n",
    "model.compile(optimizer=Adadelta(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary to check the architecture\n",
    "model.summary()\n",
    "\n",
    "# Example training call, replace x_train, y_train, x_val, y_val with your data\n",
    "# model.fit(x_train, y_train, epochs=5000, validation_data=(x_val, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assuming imagePaths is defined and filled with your image paths as before\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    # Extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    # Load the image\n",
    "    image = cv2.imread(imagePath)\n",
    "    # Convert it to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Resize it to be a fixed 60x60 pixels, ignoring aspect ratio\n",
    "    image = cv2.resize(image, (60, 60))\n",
    "    # Add a channel dimension:\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    # Update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert the data and labels to NumPy arrays while scaling the pixel intensities to the range [0, 1]\n",
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basemodel_2 (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Model parameters\n",
    "num_filters = 32  # Starting with more filters since the image is larger\n",
    "kernel_size = (3, 3)  # Smaller kernel size\n",
    "dropout_rate = 0.5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Input shape is larger now\n",
    "input_shape = (224, 224, 1)  # Adjust the last dimension if your images are RGB\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(num_filters, kernel_size, activation='relu', input_shape=input_shape, padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(num_filters * 2, kernel_size, activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(num_filters * 4, kernel_size, activation='relu', padding='same'),\n",
    "    # Removed one pooling layer to prevent too much downsampling\n",
    "    \n",
    "    Conv2D(num_filters * 8, kernel_size, activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),  # Final pooling layer\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(dropout_rate),\n",
    "    Dense(2, activation='softmax')  # Adjust based on your number of classes\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basemodel 3 (DCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Add, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_cnn_stream(input_shape):\n",
    "    \"\"\"\n",
    "    Create a CNN stream with skip connections.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Conv Block 1\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    skip_1 = x  # Skip connection\n",
    "    \n",
    "    # Conv Block 2\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    skip_2 = x  # Skip connection\n",
    "    \n",
    "    # Conv Block 3 - With skip connection from Block 1\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Add()([x, skip_1])  # Adding skip connection\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # Conv Block 4 - With skip connection from Block 2\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Add()([x, skip_2])  # Adding skip connection\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=x)\n",
    "\n",
    "# Assuming grayscale images\n",
    "input_shape = (224, 224, 1)\n",
    "\n",
    "# Create two streams\n",
    "stream1_model = create_cnn_stream(input_shape)\n",
    "stream2_model = create_cnn_stream(input_shape)\n",
    "\n",
    "# Assuming you're merging features from both streams\n",
    "combined = concatenate([stream1_model.output, stream2_model.output])\n",
    "\n",
    "# Flatten and add dense layers for classification\n",
    "x = Flatten()(combined)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)  # Binary classification output\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=[stream1_model.input, stream2_model.input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
